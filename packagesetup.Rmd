---
title: "package_setup"
author: "joshmschmidt"
date: "03/04/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#### Setting up this package
follow steps here: https://happygitwithr.com/new-github-first.html

```{r, eval=FALSE}
library(devtools)
library(usethis)
library(roxygen2)
library(ggplot2)
library(data.table)
use_description()
use_namespace()
  usethis::use_package("roxygen2")
usethis::use_package("data.table")
usethis::use_package("Rcpp")
usethis::use_package("pacman")
usethis::use_package("parallel")
usethis::use_package("NMOF")
usethis::use_package("DescTools")
usethis::use_package("Matrix")
usethis::use_package("RcppArmadillo")
usethis::use_package("RcppEigen")
devtools::document()
usethis::use_rcpp()
usethis::use_rcpp_eigen()
usethis::use_rcpp_armadillo()
usethis::use_rcpp_eigen()

```


then add R folder to project directory, manually in R file finder

```{bash Generate msms example data, eval=FALSE}
# mu = 1e-8; rho = mu; locuslength = 20e6;Ne = 1e4; s = 0.01; additive;
# samples 30 ingroup, 1 outgroup chromosomes = 31.
msms="/Users/joshua_schmidt/msms/lib/msms.jar"
out="${HOME}/Documents/acad/acad_projects/phisweepr/inst/extdata"
java -Xmx6G -jar ${msms} 31 1 -t 8000 -r 8000 20000001 -I 2 30 1 0.01 -SAA 200 -SaA 100  -Sc 0 2 0 0 0 -SF 0 -N 10000 -seed 101010 -Smark -Sp 0.5 -oFP 0.00000000 > ${out}/msms.selection.outgroup.txt

discoal="/Users/joshua_schmidt/Documents/acad/acad_projects/selection.statistics/projectBins/discoal/discoal" 
${discoal} 31 1 1000000 -t 400 -r 400 -p 2 30 1 -ed 0.05 0 1 -ws 0.00 -a 200 -x 0.5 -c 0.7 -i 4 > ${out}/discoal.selection.outgroup.txt

discoal="/Users/joshua_schmidt/Documents/acad/acad_projects/selection.statistics/projectBins/discoal/discoal" 
${discoal} 31 1 1000000 -t 400 -r 400 -p 2 30 1 -ed 0.05 0 1 -ws 0.00 -a 200 -x 0.5 -c 0.7 -i 4 > ${out}/discoal.neutral.outgroup.txt

``` 

```{r read in and process a basic msms selection scan, eval=FALSE}
ms.data <- "/Users/joshua_schmidt/Documents/acad/acad_projects/phisweepr/inst/extdata/msms.selection.outgroup.txt"
discoal.data <- "/Users/joshua_schmidt/Documents/acad/acad_projects/phisweepr/inst/extdata/discoal.selection.outgroup.txt"
#example.data <- get.ms.output(ms.file = ms.data)
example.data <- get.simulated.data(discoal.data, "discoal")
usethis::use_data(example.data, name="simData",internal = TRUE,overwrite = TRUE)
```

### NOTE *****
Check makevars file - if it has openmp, it will fuck up on mac, as clang does not support it.

```{r sfs object from genome object}
library(devtools)
library(usethis)
library(roxygen2)
library(data.table)
library(ggplot2)
library(viridis)
library(cowplot)
library(Matrix)
# genome object is example.data
# idea is to have a toplevel function 'calculate_SFSs', which returns a list object with 1-d SFS, 2-d SFS, empirical and theoretocal 
# have to estimate the mutation rate. using pi.
#load_all()
source('R/sfs_functions.R')
source('R/utilityFunctions.R')
source('R/MLconfig_functions.R')
Rcpp::sourceCpp('src/rcpp_sfs_functions.cpp')
Rcpp::sourceCpp('src/armaCubeFields.cpp')
Rcpp::sourceCpp('src/MLconfig_cpp_functions.cpp')
Rcpp::sourceCpp('src/ML_compute_cpp.cpp')
```


##### What are the different options we an have
estimate the SFS form the data, or assume the neutral equilibrium model.  
whether to use all sites or only polymorphic sites (and within that the use of fixed derived)  


```{r Vy + Kim generation of equilibirum SFS, fig.height= 5, fig.width= 15}
load("data/example.data.rda")
one_dimensional_sfs <- get_sfsDcountList(example.data$genotypes, fixed_derived = FALSE)
mutation_rate <- theta_from_pi(one_dimensional_sfs[["derived_allele_counts"]],nSam = example.data$sample.size, locusLength = example.data$locusLength)

dataObject <- example.data
dataObject[["derived_allele_counts"]] <- Matrix::diff(dataObject$genotypes@p)
n1Min <- round(dataObject$sample.size*0.25)
n1Max <- round(dataObject$sample.size*0.75)
n1range <- n1Min:n1Max
binomial.coeffs <- CbTable(dataObject$sample.size)
subP <- subPop_freqSpec(binomial.coeffs,dataObject$sample.size)
pHomo <- calc_pHomo(binomial.coeffs,dataObject$sample.size,n1Max,n1Min)
## can get the same thing as.....
subP_2 <- Matrix::Matrix(do.call(rbind,lapply(0:dataObject$sample.size,function(x) {sfs <- numeric(dataObject$sample.size+1); if(x > 1) {sfs[1:x] <-  1/(0:(x-1))}; sfs[1] <- 0; sfs })),sparse = TRUE)
# these are very close in values, down to 2e-7 at WORST.
unlist(lapply(1:31, function(x) all.equal(subP[x,],subP_2[x,],tolerance = 2e-7)))


## empirical conditional SFS
# i have two functions. one returns a single DT, the other a list of matrices.
#obs.cond.2d.sfs <- get_two_dimensionalSFSDT(dataObject = dataObject,n1Min = 1,n1Max = 30,monomorphic = FALSE,fixedDerived = FALSE)
obs.cond.2d.sfsL <- get_two_dimensionalSFSlist(dataObject = dataObject,n1Min = 1,n1Max = 30,monomorphic = FALSE,fixedDerived = FALSE)
nkMatrix <- getSfs_perN_from_two_dimensionalSFSlist(two_dimensionalSFSlist = obs.cond.2d.sfsL,monomorphic = FALSE,fixedDerived = FALSE)

# calculate phiN
# from observed
obsPhiNTable <- listMatricesToArmaCube(sfslist = obs.cond.2d.sfsL,n1Range = n1range,nSam = dataObject$sample.size)
# assumed equilibirum sfs
expPhiNTable <- standardNeutralJointSFSArmaCube(CbTable = binomial.coeffs,pHomo = pHomo, n1Min = n1Min, n1Max = n1Max, nSam = dataObject$sample.size,theta = mutation_rate, monomorphic = FALSE,fixedDerived = FALSE)

# calculate phiS!

alphaDres=4
getPhiS <- function(dataObject, nkMatrix, n1range, alphaDres=alphaDres,beta=1){
  nSam=dataObject$sample.size
  alphad_seq = seq.log10(0.001, 10, length.out = alphaDres*100+2, add.zero = TRUE)
  log10_alphad=round(log10(alphad_seq),2)
  nlog10_alphad = 0:(length(log10_alphad)-1)
  names(nlog10_alphad) = log10_alphad
  phiSTable <- makePhiSTable(nSam = nSam,testN1s = n1range, ptable = nkMatrix, alphad = 10^log10_alphad,1)
  # pass 10^log10_alphaD to phiS functions.
}

# define params for ML calculation
# first is resolution of alpha maximisiation
alpha_levels <- c(-6,-2,40)
pEscapeLim = 0.5 # 90% pescape of a single lineage
alphad_max_d <- maxd_byAlpha(alphaParVec=alpha_levels,pEscapeLim = pEscapeLim)

# define sites to ML
core_snps_idxs <- which(dataObject$derived_allele_counts %in% n1range)
low_alpha <- -6
# sel_idx <- which(dataObject$phys_pos==round(dataObject$locusLength/2))
# sel_idx %in% core_snps_idxs
test_dens <- 1

#ml_phir
core_idx = core_snps_idxs[170]
n1 <- dataObject$derived_allele_counts[core_idx]
n2 <- dataObject$sample.size - n1
core_pos <- dataObject$phys_pos[core_idx]
core_window_idxs <- which(abs(dataObject$phys_pos-core_pos) <= distance_pESingle_C(10^low_alpha,1,pEscapeLim) )
# idx of core within core_window_idxs
core_idx_in_window <- which(core_window_idxs==core_idx)
#core_n1 <- test$n1counts[core_snps_idxs[i]]
rowslice <- which(dataObject$genotypes[,core_idx]!=0)
k1 <- factorToInt(factor(diff(dataObject$genotypes[rowslice,core_window_idxs]@p),levels = 0:n1)[-core_idx_in_window])
k2 <- factorToInt(factor(diff(dataObject$genotypes[-rowslice,core_window_idxs]@p),levels = 0:n2)[-core_idx_in_window])
pos.vec <- dataObject$phys_pos[core_window_idxs][-core_idx_in_window]
dist.vec <- abs(pos.vec-core_pos)
# then into ml function; brute force
# above is defined the maximumm window. as we move along alpha, this window reduces and we trim it.
# setups grid for LratioCalcPhi
#optimFun parVec= c(10^x[1], x[2])
parVec= c(10^-6,1)

test_alpha <- round(parVec[1],10)
test_beta <- parVec[2]
alpha_core_sub_idxs <- subsetKcountWindow_probEscape_C(dist.vec,test_alpha,test_beta,pEscapeLim)
if (alpha_core_sub_idxs[2]-alpha_core_sub_idxs[1] < 6) {
  return(1) # check this is the right value to return!
}

sub_partition_k1_counts <- k1[alpha_core_sub_idxs[1]:alpha_core_sub_idxs[2]]
sub_partition_k2_counts <- k2[alpha_core_sub_idxs[1]:alpha_core_sub_idxs[2]]
sub_dist.vec <- dist.vec[alpha_core_sub_idxs[1]:alpha_core_sub_idxs[2]]
sub_alphaD.vec = round(log10(sub_dist.vec*test_alpha), 2);
sub_alphaD.vec[which(sub_alphaD.vec < log10_alphad[2])] <- log10_alphad[1]
sub_alphaD.vec[which(sub_alphaD.vec > log10_alphad[length(log10_alphad)])] <- log10_alphad[length(log10_alphad)]
sub_alphaD_idx <- match(sprintf("%0.2f", sub_alphaD.vec), sprintf("%0.2f", log10_alphad))-1
## monomorphoc positions!
log(getProbVector(phitable = phiSTable, n1 = n1, minN1 = 8,k1 = k1,k2 = k2,sub_alphaD_idx = sub_alphaD_idx))

log10_alphad
# procedure for adding monomorphic sites! only if option!
sub_partition_k_counts <- addMonomorphicPhiS(sub_partition_k_counts,
                                                 mono_sites)
# fold the distances. think this was to reduce the number of discrete sites....
maxd <- alphad_comb_list[[1]][alpha==eval(test_alpha),max_d]
sub_partition_k_counts[d > maxd,d:=maxd]

#
LLvec_neu <- log(phiN_hash[[sub_partition_k_counts[,paste(eval(n1),k1,
                                                              eval(n2),k2)]]])
    sub_partition_k_counts<- sub_partition_k_counts[d!=0,log10_alphad:=round(alphad_comb_list[[2]][[paste(test_beta,test_alpha,d)]],2) ]
   




# got all my k1 and k2 counts now.....
partition_k_counts[,pos:= pos_vec[core_window_idxs]]
    
    # add position relative to core snp.


```

```{r }
#alphaDres c(1,2,4)
# plot escape probabilty curve
calcAlpha <- function(N,r,s) {
    alpha <- (r*log(2*N))/s
    return(log10(alpha))
}


s<-c(0.005,0.001)
col<-viridis(length(s)+1)[-3]
for(i in seq_along(s)) {
    curve(probEscape_Single_C_plot(10^calcAlpha(1e3,1e-8,s[i]),beta = 1,d=x),-0.5e6,0.5e6,n = 500, add=i!=1, col=col[i], main="Reduction of diveristy due to a selective sweep",lwd=2.5,ylab='Pr. escape a sweep',xlab='distance from sweep (bp)')
}
legend('right',legend = s, col=col, lty=1,title = 'selection coefficient',bty='n')


```

```{r convert obs cube slice to data.table and plot}
cols <- viridis(10)
# can convert a slice to a long formatDT
obsSFSlong <- matrixToLongDT(obs.cond.2d.sfsL[[16]],n1 = 15,n2 = 15)
pObs <- ggplot(obsSFSlong, aes(k1, k2)) +
  geom_tile(aes(fill = log10(pr))) +
  scale_fill_gradientn(colours = cols) + coord_equal()
```

```{r convert exp cube slice to data.table and plot}
expSFSlong <- matrixToLongDT(neutralExpSfsCube[,,8],n1 = 15,n2 = 15)

pExp <- ggplot(expSFSlong, aes(k1, k2)) +
  geom_tile(aes(fill = log10(pr))) +
  scale_fill_gradientn(colours = cols) + coord_equal()
```

```{r find residuals and plot}
# residuals
setkey(obsSFSlong,n1,k1,k2)
setkey(expSFSlong,n1,k1,k2) 
comSFSlong <- obsSFSlong[expSFSlong]
comSFSlong[,residual:=pr-i.pr]
pRes <- ggplot(comSFSlong, aes(k1, k2)) +
  geom_tile(aes(fill = residual)) +
  scale_fill_gradientn(colours = cols) + coord_equal()

plot_grid(pExp, pObs, pRes,nrow = 1,labels = c('expected', 'observed', 'residuals: obs-exp'),align = "hv")
```



```{r after selection}
neartosweep <- matrixToLongDT(phiSTable[,,4,1],11,19)
midtosweep <- matrixToLongDT(phiSTable[,,4,51],11,19)
fartosweep <- matrixToLongDT(phiSTable[,,4,102],11,19)


pNear <- ggplot(neartosweep, aes(k1, k2)) +
  geom_tile(aes(fill = log10(pr))) +
  scale_fill_gradientn(colours = cols) + coord_equal()
  
pMid <- ggplot(midtosweep, aes(k1, k2)) +
  geom_tile(aes(fill = log10(pr))) +
  scale_fill_gradientn(colours = cols) + coord_equal()
  
pFar <- ggplot(fartosweep, aes(k1, k2)) +
  geom_tile(aes(fill = log10(pr))) +
  scale_fill_gradientn(colours = cols) + coord_equal()
  pdf(file = 'effect.sweep.pdf',width = 18,height = 5)
  plot_grid(pFar, pMid, pNear,nrow = 1,labels = c('far', 'midway', 'near'),align = "hv")
  dev.off()
```



```{r expand.grid in r}
n1 <- 22
n2 = 30 - 22
k1 <- 0:n1
k2 <- 0:n2
l <- length(k1) * length(k2)
a <- array(dim=c(l,2))
for(j in seq_along(k2)){
  
}
```

